{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os.path as osp\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from typing import List, Optional, Set, get_type_hints\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "from torch_scatter import gather_csr, scatter, segment_csr\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Sequential, ReLU, Linear, Dropout, BatchNorm1d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# from src.data_preparation import RWDataset, data_gen_e_aug\n",
    "# from src.models import GraphNet, add_weight_decay\n",
    "# from src.utils import create_nx_graph,create_gt_graph, draw_deg_distr, relabel, init_graph\n",
    "# from src.utils import sel_start_node, sel_start_node_old, get_errors\n",
    "# from src.train import LabelSmoothing\n",
    "# from src.utils import NodeSelector\n",
    "from src.model import GPT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def load_PYG_datasets(path, d_name = 'PROTEINS'):\n",
    "    pth = path\n",
    "    path = osp.join(pathlib.Path().absolute(), pth , d_name)\n",
    "    dset = TUDataset(path, d_name)\n",
    "    \n",
    "    #sozdal otdelno pole features, a v pole x pomestil indexi - t.k. vektora vershin u nas menyayutsya\n",
    "    dset.features = dset.data.x \n",
    "    dset.data.x = torch.arange(dset.data.x.shape[0])\n",
    "    return dset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "dset = load_PYG_datasets(path='./data/proteins', d_name='PROTEINS')\n",
    "\n",
    "#dset = RWDataset('')  random walks for Cora"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "BSIZE = 16\n",
    "train_loader = DataLoader(dset, batch_size=BSIZE, shuffle=False)# , exclude_keys=['x']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "def data_gen_e_aug(train_loader, slices, batch_size = 4, step = 1):\n",
    "    r\"\"\" berem skleennie graphi, iteriruem po vershinam, stroim augmented graph\n",
    "\n",
    "    Args:\n",
    "        train_loader: PyG DataLoader\n",
    "        slices: indexy reber, po kotorim skleivali nabor graphov\n",
    "        batch_size:\n",
    "        step: po skolko reber narashivaem graph, obichno 1\n",
    "    Outputs:\n",
    "        vi: indexi vershin v ishodnom graphe\n",
    "        graph: augmented graph\n",
    "        edges: priroshennie rebra\n",
    "    \"\"\"\n",
    "    \n",
    "    for ib, data in enumerate(train_loader):\n",
    "        print(data)\n",
    "        e_ptr = slices[ib*batch_size:(ib+1)*batch_size+1]\n",
    "        e_ptr = e_ptr - e_ptr[0]\n",
    "        szs = e_ptr[1:]-e_ptr[:-1]\n",
    "        e_ind_start = e_ptr[1:]-szs.min()+1\n",
    "        visited_e = torch.full((e_ptr[-1],), False, dtype = torch.bool)\n",
    "        for i in range(e_ind_start.shape[0]):\n",
    "            visited_e[e_ptr[:-1][i] :e_ind_start[i]] = True # setting emask True for edges in graph\n",
    "        edges_num = torch.arange(e_ptr[-1])\n",
    "        \n",
    "        visited_v = torch.full((data.ptr[-1],), False)\n",
    "        visited_v[torch.unique(data.edge_index[:, visited_e])] = True\n",
    "        \n",
    "        vert_base = torch.where(visited_v)[0]\n",
    "        \n",
    "        vert_ind,v_feature_ind = [], []\n",
    "        last_ind_v = torch.arange(data.ptr[-1])\n",
    "        last_ind_max = data.ptr[-1].item()        \n",
    "        ei_dict = defaultdict(set)\n",
    "        for e in data.edge_index[:, visited_e].T:\n",
    "            e = e.to(dtype=torch.long)\n",
    "            ei_dict[e[0].item()].add(e[1].item()) \n",
    "            ei_dict[e[1].item()].add(e[0].item()) \n",
    "        edge_added = []\n",
    "        \n",
    "        for i in range(data.edge_index.shape[1]): # max number of iterations, usually we stop earlier\n",
    "            if torch.all(visited_e):\n",
    "                break           \n",
    "                  \n",
    "            e1_mask = (visited_v[data.edge_index[0]] | visited_v[data.edge_index[1]]) & ~visited_e # Source in graph\n",
    "            nnedges = edges_num[e1_mask]\n",
    "            e1_ind = []\n",
    "            for j in range(1, e_ptr.shape[0]):\n",
    "                mmask = (nnedges < e_ptr[j]) & (nnedges >= e_ptr[j-1])\n",
    "                e1_ind.append(nnedges[mmask][:step])         \n",
    "            e1_ind = torch.cat(e1_ind)\n",
    "            edges_1 = data.edge_index[:, e1_ind]\n",
    "            \n",
    "            for e in edges_1.T: \n",
    "                e_reind = []\n",
    "                edge_added.append(last_ind_v[e].view(-1,1))\n",
    "                \n",
    "                for iv in (True,False):\n",
    "                    ind = last_ind_v[e[int(iv)]].item()\n",
    "                    vert_ind.append(ind)\n",
    "                    v_feature_ind.append(e[int(iv)])\n",
    "                    if ind in ei_dict.keys():\n",
    "                        ind = last_ind_max                        \n",
    "                        last_ind_v[e[int(iv)]] = ind\n",
    "                        ei_dict[ind] = ei_dict[e[int(iv)].item()]   \n",
    "                        last_ind_max += 1  \n",
    "                    e_reind.append(ind)\n",
    "                    \n",
    "                ei_dict[e_reind[0]].add(e_reind[1]) #sporno\n",
    "                ei_dict[e_reind[1]].add(e_reind[0])\n",
    "        \n",
    "            # selecting source-target when both vertices in graph            \n",
    "            visited_e[e1_ind] = True  \n",
    "            visited_v[edges_1.view(-1)] = True\n",
    "        \n",
    "        edge_index = []\n",
    "        for k,v in ei_dict.items():\n",
    "            e = torch.tensor(list(v)).view(1,-1)\n",
    "            edge_index.append(torch.cat((e, torch.full_like(e, k)), dim=0))\n",
    "\n",
    "\n",
    "        yield  data.x[torch.cat((torch.Tensor(v_feature_ind).to(dtype=torch.long),vert_base))],\\\n",
    "                torch.cat((torch.Tensor(vert_ind).to(dtype=torch.long),last_ind_v)), \\\n",
    "                torch.cat(edge_added, dim=1),\\\n",
    "                torch.cat(edge_index, dim=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "for ib, data in enumerate(train_loader):\n",
    "    print(data.ptr)\n",
    "    szs =data.ptr[1:]-data.ptr[:-1]\n",
    "    r = repeat(torch.arange(szs.max()), 'h -> h c', c=16).T\n",
    "    mask = r < szs.unsqueeze(1)\n",
    "    print(mask.shape, mask)\n",
    "    \n",
    "#     print(r.shape,data.ptr[1:].unsqueeze(1).shape)\n",
    "#     print(szs.max())\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([  0,  42,  69,  79, 103, 114, 450, 558, 712, 731, 742, 762, 814, 835,\n",
      "        879, 899, 939])\n",
      "torch.Size([16, 336]) tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "szs =e_ptr[1:]-e_ptr[:-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "train_gen = data_gen_e_aug(train_loader, dset.slices['edge_index'], batch_size = BSIZE,step = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "itt = iter(train_gen)\n",
    "vi, vj, e1, graph = next(itt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch(batch=[939], edge_index=[2, 3928], ptr=[17], x=[939], y=[16])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "vi.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1964])"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "vj.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1995])"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "device = torch.device('cpu')\n",
    "    \n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "arch0 = {'input_dim': dset.features.shape[1], \n",
    "        'hidden_dim': 32,\n",
    "        'num_layers': 2,\n",
    "        'num_heads': 8,\n",
    "        'attn_pdrop': 0.5,\n",
    "        'resid_pdrop': 0.5,\n",
    "        'embd_pdrop': 0.5,\n",
    "        'gnn_pdrop': 0.5,\n",
    "        'num_gnn_layers': 1,\n",
    "        'mlp_pdrop': 0.5}\n",
    "conf = objectview(arch0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, dropout_p = 0.2):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(num_features=hidden_dim))\n",
    "            \n",
    "    def forward(self, v_ind, features, edge_index):\n",
    "        x = features[v_ind]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.lin = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z_true, z_concat):\n",
    "        h = torch.abs(z_true - self.lin(z_concat)) \n",
    "\n",
    "        return self.lin_final(h)\n",
    "    \n",
    "    \n",
    "class SRAN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SRAN, self).__init__()\n",
    "\n",
    "        self.input_dim = config.input_dim\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.num_layers = config.num_layers\n",
    "        self.num_heads = config.num_heads\n",
    "        self.attn_pdrop = config.attn_pdrop\n",
    "        self.resid_pdrop = config.resid_pdrop\n",
    "        self.embd_pdrop = config.embd_pdrop\n",
    "        self.gnn_pdrop  = config.gnn_pdrop\n",
    "        self.num_gnn_layers = config.num_gnn_layers\n",
    "        self.mlp_pdrop = config.mlp_pdrop\n",
    "\n",
    "        self.lin_inp = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_dim)\n",
    "#             nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "#             nn.Dropout(self.mlp_pdrop)\n",
    "        )\n",
    "\n",
    "        self.gnn = GraphNet(\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_layers=self.num_gnn_layers,\n",
    "        )\n",
    "\n",
    "        self.gpt = GPT(\n",
    "            hidden_dim=2 * self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            attn_pdrop=self.attn_pdrop,\n",
    "            resid_pdrop=self.resid_pdrop,\n",
    "            embd_pdrop=self.embd_pdrop\n",
    "        )\n",
    "        \n",
    "        self.lp = LinkPredictor(2 * self.hidden_dim)\n",
    "        \n",
    "    def forward(self, v_ind, features, edge_index, edges):\n",
    "        feat = self.lin_inp(features)\n",
    "        print(v_ind.shape)\n",
    "\n",
    "        gnn_feat = self.gnn(v_ind, feat, edge_index) # (N,d)\n",
    "\n",
    "        edge_embs_true = rearrange(gnn_feat[edges], \n",
    "                                   'e batch n_seq d -> n_seq batch (d e)')# (S, N, d)\n",
    "        next_edge_embs = self.gpt(edge_embs_true[:-1])\n",
    "        \n",
    "\n",
    "        return next_edge_embs\n",
    "\n",
    "\n",
    "        \n",
    "#         h_next_e = self.gpt(torch.cat((h_source, h_target)))\n",
    "        \n",
    "# #         y_source = self.choice(self.mlp_y_s(h_next_e), h_source) # сместить на 1 позицию\n",
    "# #         z_target = self.mlp_y_t(torch.cat((h_next_e, h_source))) #а здесь не смещаить h_source?\n",
    "# #         y_target = self.choice(z_target, h_target)\n",
    "        \n",
    "#         return h_next_e\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "model = SRAN(conf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "y = model(vi, dset.features, graph, e1.view(2, BSIZE,-1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1964])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "e1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  33,   59,   69,  ..., 1927, 1929, 1931],\n",
       "        [  34,   61,   71,  ..., 1799, 1833, 1867]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "dset.features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "v1 = torch.randn(100)\n",
    "v2 = torch.randn(100)\n",
    "tensors = rearrange([v1, v2], 'b a -> a b')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "(v1.unsqueeze(2) - v2.unsqueeze(1)).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 16])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "repeat(v1, 'a b -> a b c', c=16).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 16])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "rearrange(v1, 'a b -> b a 1').shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "batch_size = 16\n",
    "Nvert = 100\n",
    "d = 32\n",
    "\n",
    "v1 = torch.zeros(batch_size, Nvert, d)\n",
    "v2 = torch.ones(batch_size, Nvert, d)\n",
    "z1 = repeat(v1, 'b a d -> b a c d', c = Nvert)\n",
    "z2 = repeat(v2, 'b a d -> b c a d', c = Nvert)\n",
    "print(z1.shape, z2.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 100, 100, 32]) torch.Size([16, 100, 100, 32])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "tensors = rearrange([z1,z2], 'e b x y d -> b x y (e d)')\n",
    "tensors.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 100, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "tensors[0, 1,1,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# eshe ne pravil!!!!\n",
    "\n",
    "def train(sampler, mod, optimizer, data, bsz):\n",
    "    mod.train()\n",
    "        \n",
    "    loss = 0   \n",
    "    encoded_features = mod.encode(data.x.to(device = mod.device))\n",
    "\n",
    "    ii=0\n",
    "    for inp in sampler(data, batch_size = bsz):\n",
    "        ii +=1\n",
    "        encoded_features = mod.encode(data.x.to(device = mod.device))\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        pred_e, targ_e, w0 = mod.iterate(data, inp, encoded, bsz) \n",
    "#         n_1.append(targ_e.sum())\n",
    "#         num_e.append(pred_e.shape[0])\n",
    "        if mod.label_smooth:\n",
    "            loss += cal_edge_loss(pred_e, targ_e)\n",
    "        else:\n",
    "            loss += F.binary_cross_entropy_with_logits(pred_e, targ_e)    \n",
    "#             loss += F.binary_cross_entropy_with_logits(pred_e, targ_e, \n",
    "#                                                        pos_weight = torch.tensor([w0], device = mod.device))    \n",
    "            \n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "#     d_train\n",
    "    train(data_gen_edges_dyn, model, optimizer, data, B_SIZE)\n",
    "#     train(data_gen_edges_dyn, model, optimizer, d_train, B_SIZE)\n",
    "#     train(data_gen_edges_dyn, model, optimizer, data, B_SIZE)\n",
    "#     acc_e_test = test( data_gen_edges_dyn, model, d_test, 1)\n",
    "#     acc_e_test = test( data_gen_edges_dyn, model, data, 1)\n",
    "#     acc = acc_e_test.mean()\n",
    "#     print(acc, np.median(acc_e_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# eshe ne pravil!!!!\n",
    "@torch.no_grad()\n",
    "def test(sampler,mod, data, bsz, return_y = False, dtype = 'test'):\n",
    "    mod.eval()\n",
    "        \n",
    "    out = []\n",
    "    n_1, acc_e,num_e = [],[],[]\n",
    "    # init_state = torch.zeros((data.num_nodes*bsz,  mod.nd), device=mod.device)\n",
    "    encoded = mod.encode(data.x.to(device = mod.device))\n",
    "    indd = torch.cat(bsz*[torch.arange(data.num_nodes, device = mod.device)])\n",
    "    mod.reset_state(encoded[indd,:])\n",
    "    for inp in sampler(data, batch_size = bsz, step_max = 512, dtype = dtype):\n",
    "        pred_e, targ_e, w0 = mod.iterate(data, inp, encoded, bsz) \n",
    "        if return_y:\n",
    "            out.append((pred_e, targ_e, w0))#, dim=1\n",
    "        pred_e = torch.round(torch.sigmoid(pred_e))\n",
    "#         print('pred_e', pred_e)\n",
    "        tp_e = pred_e.eq(targ_e).sum().item()\n",
    "        n_e = pred_e.shape[0]\n",
    "        \n",
    "        n_1.append(targ_e.sum())\n",
    "\n",
    "        acc_e.append(tp_e)\n",
    "        num_e.append(n_e)\n",
    "        \n",
    "    if return_y:\n",
    "        return out\n",
    "    else:\n",
    "        return  np.array(acc_e)/(np.array(num_e)+1e-9)\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebb52467e1dc0a47a043b51a32f48de2b8bb954aeb608c05cd7a9afa0d7ebeae"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('genv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}