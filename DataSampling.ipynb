{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "from typing import List, Optional, Set, get_type_hints\n",
    "from torch_scatter import gather_csr, scatter, segment_csr\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(MessagePassing):\n",
    "    def __init__(self, **kwargs):  # yapf: disable\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(MyConv, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj, deg: Tensor,\n",
    "                size: Size = None) -> Tensor:\n",
    "        \n",
    "        x = torch.cat((x, deg.view(-1,1)), dim=1)\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)      \n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "    \n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  ptr: Optional[Tensor] = None,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        r\"\"\"Aggregates messages from neighbors as\n",
    "        :math:`\\square_{j \\in \\mathcal{N}(i)}`.\n",
    "\n",
    "        Takes in the output of message computation as first argument and any\n",
    "        argument which was initially passed to :meth:`propagate`.\n",
    "\n",
    "        By default, this function will delegate its call to scatter functions\n",
    "        that support \"add\", \"mean\" and \"max\" operations as specified in\n",
    "        :meth:`__init__` by the :obj:`aggr` argument.\n",
    "        \"\"\"\n",
    "        if ptr is not None:\n",
    "            ptr = expand_left(ptr, dim=self.node_dim, dims=inputs.dim())\n",
    "            return segment_csr(inputs, ptr, reduce=self.aggr)\n",
    "        else:\n",
    "            print(inputs, index)\n",
    "            return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                           reduce=self.aggr)\n",
    "        \n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GENConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        kwargs.setdefault('aggr', None)\n",
    "        super(GENConv, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "        if self.msg_norm is not None:\n",
    "            out = self.msg_norm(x[0], out)\n",
    "        x_r = x[1]\n",
    "        if x_r is not None:\n",
    "            out += x_r\n",
    "        return self.mlp(out)\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: OptTensor) -> Tensor:\n",
    "        return F.relu(msg) + self.eps\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "\n",
    "        out = scatter_softmax(inputs * self.t, index, dim=self.node_dim)\n",
    "        return scatter(inputs * out, index, dim=self.node_dim,\n",
    "                           dim_size=dim_size, reduce='sum')\n",
    "\n",
    "#         elif self.aggr == 'softmax_sg':\n",
    "#             out = scatter_softmax(inputs * self.t, index,\n",
    "#                                   dim=self.node_dim).detach()\n",
    "#             return scatter(inputs * out, index, dim=self.node_dim,\n",
    "#                            dim_size=dim_size, reduce='sum')\n",
    "\n",
    "#         else:\n",
    "#             min_value, max_value = 1e-7, 1e1\n",
    "#             torch.clamp_(inputs, min_value, max_value)\n",
    "#             out = scatter(torch.pow(inputs, self.p), index, dim=self.node_dim,\n",
    "#                           dim_size=dim_size, reduce='mean')\n",
    "#             torch.clamp_(out, min_value, max_value)\n",
    "#             return torch.pow(out, 1 / self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = [(0,13),(0,5),(0,14),(13,1),(0,18),(0,8),(14,7),(0,11),(0,3),\n",
    "         (3,10),(0,19),(11,4),(1,9),(9,12),(0,12),(3,7),(0,16),(11,8),\n",
    "         (1,3),(1,6),(0,13),(14,13),(11,15),(0,12),(4,17),(11,12),(3,2)]\n",
    "ei = torch.tensor(el).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_dict = defaultdict(set)\n",
    "for e in ei.T:\n",
    "    e = e.to(dtype=torch.long)\n",
    "    ei_dict[e[0]].add(e[1]) \n",
    "    ei_dict[e[1]].add(e[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(0): {tensor(13)}}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {torch.tensor(0): {torch.tensor(13)}}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh = F.one_hot(ei[0],num_classes=20)+F.one_hot(ei[1],num_classes=20)\n",
    "oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cumsum(oh, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = ei\n",
    "adj_t = SparseTensor(row=col, col=row,\n",
    "                     sparse_sizes=(data.num_nodes, data.num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([ 1,  2,  3,  3,  4,  5,  6,  7,  7,  8,  8,  9, 10, 11, 12, 12, 12, 12,\n",
       "                           13, 13, 13, 14, 15, 16, 17, 18, 19]),\n",
       "             col=tensor([13,  3,  0,  1, 11,  0,  1,  3, 14,  0, 11,  1,  3,  0,  0,  0,  9, 11,\n",
       "                            0,  0, 14,  0, 11,  0,  4,  0,  0]),\n",
       "             size=(275, 275), nnz=27, density=0.04%)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([0, 0]),\n",
       "             col=tensor([0, 1]),\n",
       "             size=(1, 275), nnz=2, density=0.73%)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_t[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_v = torch.ones(10, 8)\n",
    "delta_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(16, 8, dtype=src.dtype).scatter_add_(0, index, src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  4,  1,  5,  2,  1,  1,  2,  2,  2,  1,  5,  4,  4,  3,  1,  1,  1,\n",
       "         1,  1])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, dg = torch.unique(ei, return_counts = True)\n",
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.9967, 0.6499, 0.4298, 0.2115, 0.7027, 0.8352, 0.6765, 0.0435, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.7772, 0.1651, 0.0392, 0.4880, 0.2471, 0.5597, 0.5317, 0.4280, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.0049, 0.0289, 0.7177, 0.0580, 0.8168, 0.5887, 0.8685, 0.2321, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.7230, 0.3680, 0.4621, 0.3198, 0.0290, 0.2466, 0.4086, 0.0826, 1.0000],\n",
      "        [0.7480, 0.2289, 0.7284, 0.9652, 0.4299, 0.1629, 0.0740, 0.6505, 1.0000],\n",
      "        [0.8849, 0.0888, 0.0959, 0.5236, 0.5322, 0.9872, 0.6792, 0.0489, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.0049, 0.0289, 0.7177, 0.0580, 0.8168, 0.5887, 0.8685, 0.2321, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.7230, 0.3680, 0.4621, 0.3198, 0.0290, 0.2466, 0.4086, 0.0826, 1.0000],\n",
      "        [0.7480, 0.2289, 0.7284, 0.9652, 0.4299, 0.1629, 0.0740, 0.6505, 1.0000],\n",
      "        [0.7480, 0.2289, 0.7284, 0.9652, 0.4299, 0.1629, 0.0740, 0.6505, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.7772, 0.1651, 0.0392, 0.4880, 0.2471, 0.5597, 0.5317, 0.4280, 1.0000],\n",
      "        [0.7230, 0.3680, 0.4621, 0.3198, 0.0290, 0.2466, 0.4086, 0.0826, 1.0000],\n",
      "        [0.3218, 0.3033, 0.4526, 0.0737, 0.3362, 0.4346, 0.5787, 0.9123, 1.0000],\n",
      "        [0.0780, 0.0532, 0.1328, 0.1744, 0.7345, 0.7418, 0.1649, 0.2961, 1.0000],\n",
      "        [0.7230, 0.3680, 0.4621, 0.3198, 0.0290, 0.2466, 0.4086, 0.0826, 1.0000],\n",
      "        [0.0049, 0.0289, 0.7177, 0.0580, 0.8168, 0.5887, 0.8685, 0.2321, 1.0000]]) tensor([13,  5, 14,  1, 18,  8,  7, 11,  3, 10, 19,  4,  9, 12, 12,  7, 16,  8,\n",
      "         3,  6, 13, 13, 15, 12, 17, 12,  2])\n"
     ]
    }
   ],
   "source": [
    "xx = torch.rand(20,8)\n",
    "y = conv(x = xx, edge_index = ei, deg = torch.ones(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(RWDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.pth = '/data/egor/graph_generation/graph_generation/data/rw/cora/graphs/'\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        self.features = torch.load(self.pth+'cora_x.pt')\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['/data/egor/graph_generation/graph_generation/data/rw/cora//cora.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        self.pth = '/data/egor/graph_generation/graph_generation/data/rw/cora/graphs/'\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        edge_list_array = []\n",
    "        \n",
    "        for ig in range(14538):\n",
    "            with open(self.pth + 'graph' + str(ig) + '.dat', 'rb') as f:        \n",
    "                G = pickle.load(f)\n",
    "                x, ei = torch.unique(torch.tensor(list(G.edges)).T, return_inverse  = True)\n",
    "                ei = to_undirected(ei)\n",
    "#                 data_list.append(Data(x = x, edge_index = ei))\n",
    "                \n",
    "                c,r = ei\n",
    "                data_list.append(Data(x = x, edge_index = ei[:,c<r]))\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSIZE = 16\n",
    "dd = RWDataset('')\n",
    "train_loader = DataLoader(dd, batch_size=BSIZE, shuffle=False)# , exclude_keys=['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_e_aug(train_loader, slices, batch_size = 4, step = 1):\n",
    "    for ib, data in enumerate(train_loader):\n",
    "#         r,c = data.edge_index\n",
    "#         print(data.edge_index)\n",
    "#         print(data.edge_index[:,r>c].shape)\n",
    "        e_ptr = slices[ib*batch_size:(ib+1)*batch_size+1]\n",
    "        e_ptr = e_ptr - e_ptr[0]\n",
    "        szs = e_ptr[1:]-e_ptr[:-1]\n",
    "        e_ind_start = e_ptr[1:]-szs.min()+1\n",
    "        visited_e = torch.full((e_ptr[-1],), False, dtype = torch.bool)\n",
    "        for i in range(e_ind_start.shape[0]):\n",
    "            visited_e[e_ptr[:-1][i] :e_ind_start[i]] = True # setting emask True for edges in graph\n",
    "        edges_num = torch.arange(e_ptr[-1])\n",
    "\n",
    "        visited_v = torch.full((data.ptr[-1],), False)\n",
    "        visited_v[torch.unique(data.edge_index[:, visited_e])] = True\n",
    "        \n",
    "        vert_ind = []\n",
    "        last_ind_v = torch.arange(data.ptr[-1])\n",
    "        last_ind_max = data.ptr[-1].item()        \n",
    "        ei_dict = defaultdict(set)\n",
    "        for e in data.edge_index[:, visited_e].T:\n",
    "            e = e.to(dtype=torch.long)\n",
    "            ei_dict[e[0].item()].add(e[1].item()) \n",
    "            ei_dict[e[1].item()].add(e[0].item()) \n",
    "        \n",
    "        for i in range(data.edge_index.shape[1]): # max number of iterations, usually we stop earlier\n",
    "            if torch.all(visited_e):\n",
    "                break           \n",
    "                  \n",
    "            e1_mask = (visited_v[data.edge_index[0]] | visited_v[data.edge_index[1]]) & ~visited_e # Source in graph\n",
    "            nnedges = edges_num[e1_mask]\n",
    "            e1_ind = []\n",
    "            for j in range(1, e_ptr.shape[0]):\n",
    "                mmask = (nnedges < e_ptr[j]) & (nnedges >= e_ptr[j-1])\n",
    "                e1_ind.append(nnedges[mmask][:step])         \n",
    "            e1_ind = torch.cat(e1_ind)\n",
    "            edges_1 = data.edge_index[:, e1_ind]\n",
    "                        \n",
    "            for e in edges_1.T: \n",
    "                for iv in (True,False):\n",
    "                    ind = last_ind_v[e[int(iv)]].item()\n",
    "                    if ind in ei_dict.keys():\n",
    "                        ind = last_ind_max\n",
    "                        vert_ind.append(e[int(iv)])\n",
    "                        last_ind_v[e[int(iv)]] = ind\n",
    "                        ei_dict[ind] = ei_dict[e[int(iv)].item()]   \n",
    "                        last_ind_max += 1                        \n",
    "                    ei_dict[ind].add(last_ind_v[e[int(~iv)]].item())\n",
    "        \n",
    "            # selecting source-target when both vertices in graph            \n",
    "            visited_e[e1_ind] = True  \n",
    "            visited_v[edges_1.view(-1)] = True\n",
    "        \n",
    "        edge_index = []\n",
    "        for k,v in ei_dict.items():\n",
    "            e = torch.tensor(list(v)).view(1,-1)\n",
    "            edge_index.append(torch.cat((e, torch.full_like(e, k)), dim=0))\n",
    "        vert_index = torch.cat((torch.arange(data.ptr[-1]),torch.Tensor(vert_ind))).to(dtype=torch.long)\n",
    "\n",
    "        yield  data.x[vert_index],\\\n",
    "                torch.cat(edge_index, dim=1)\n",
    "        \n",
    "        \n",
    "itt = iter(data_gen_e_aug(train_loader, dd.slices['edge_index'], batch_size = BSIZE,step = 1))\n",
    "vi, ei = next(itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  15,   62,  121,  ..., 1906, 2355, 2342])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 83]) torch.Size([2, 4])\n",
      "torch.Size([2, 87]) torch.Size([2, 4])\n",
      "torch.Size([2, 91]) torch.Size([2, 4])\n",
      "torch.Size([2, 95]) torch.Size([2, 4])\n",
      "torch.Size([2, 99]) torch.Size([2, 4])\n",
      "torch.Size([2, 103]) torch.Size([2, 4])\n",
      "torch.Size([2, 107]) torch.Size([2, 4])\n",
      "torch.Size([2, 111]) torch.Size([2, 4])\n",
      "torch.Size([2, 115]) torch.Size([2, 4])\n",
      "torch.Size([2, 119]) torch.Size([2, 4])\n",
      "torch.Size([2, 123]) torch.Size([2, 4])\n",
      "torch.Size([2, 127]) torch.Size([2, 4])\n",
      "torch.Size([2, 131]) torch.Size([2, 4])\n",
      "torch.Size([2, 135]) torch.Size([2, 4])\n",
      "torch.Size([2, 139]) torch.Size([2, 4])\n",
      "torch.Size([2, 143]) torch.Size([2, 4])\n",
      "torch.Size([2, 147]) torch.Size([2, 4])\n",
      "torch.Size([2, 151]) torch.Size([2, 4])\n",
      "torch.Size([2, 155]) torch.Size([2, 4])\n",
      "torch.Size([2, 159]) torch.Size([2, 4])\n",
      "torch.Size([2, 163]) torch.Size([2, 4])\n",
      "torch.Size([2, 167]) torch.Size([2, 4])\n",
      "torch.Size([2, 171]) torch.Size([2, 4])\n",
      "torch.Size([2, 175]) torch.Size([2, 4])\n",
      "torch.Size([2, 179]) torch.Size([2, 4])\n",
      "torch.Size([2, 183]) torch.Size([2, 4])\n",
      "torch.Size([2, 187]) torch.Size([2, 4])\n",
      "torch.Size([2, 191]) torch.Size([2, 4])\n",
      "torch.Size([2, 195]) torch.Size([2, 4])\n",
      "torch.Size([2, 199]) torch.Size([2, 4])\n",
      "torch.Size([2, 203]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "def data_gen_edges(train_loader, slices, batch_size = 4, step = 1):\n",
    "    for ib, data in enumerate(train_loader):\n",
    "#         print(data)\n",
    "        e_ptr = slices[ib*batch_size:(ib+1)*batch_size+1]\n",
    "        e_ptr = e_ptr - e_ptr[0]\n",
    "#         print(ib, e_ptr)\n",
    "\n",
    "        szs = e_ptr[1:]-e_ptr[:-1]\n",
    "        e_ind_start = e_ptr[1:]-szs.min()\n",
    "        e_mask = torch.full((e_ptr[-1],), False, dtype = torch.bool)\n",
    "        for i in range(e_ind_start.shape[0]):\n",
    "            e_mask[e_ptr[:-1][i] :e_ind_start[i]] = True # setting emask True for edges in graph\n",
    "\n",
    "        for i in range(szs.min()-1): #growing the graph\n",
    "            new_ei = e_ind_start + i\n",
    "            e_mask[new_ei] = True  \n",
    "            graph = data.edge_index[:, e_mask]\n",
    "            e_1 = data.edge_index[:, new_ei]\n",
    "            print(graph.shape, e_1.shape)\n",
    "        yield graph, e_1\n",
    "        \n",
    "#                 v_add_1_mask.view((batch_size, data.num_nodes)).sum(dim=1),\\\n",
    "#                 torch.cat((v_exp_0,v_exp_1)),\\\n",
    "#                 torch.cat((v_add_0,v_add_1)), \\\n",
    "#                 torch.cat((e_0,e_1), dim=2).reshape((2,-1)).to(dtype = torch.long),\\\n",
    "#                 visited_mask.view((batch_size, data.num_nodes))        \n",
    "#     if ib>5:\n",
    "#         break\n",
    "itt = iter(data_gen_edges(train_loader, dd.slices['edge_index'], batch_size = BSIZE))\n",
    "g, e1 = next(itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_e_connected(train_loader, slices, batch_size = 4, step = 1):\n",
    "    for ib, data in enumerate(train_loader):\n",
    "        e_ptr = slices[ib*batch_size:(ib+1)*batch_size+1]\n",
    "        e_ptr = e_ptr - e_ptr[0]\n",
    "        szs = e_ptr[1:]-e_ptr[:-1]\n",
    "        e_ind_start = e_ptr[1:]-szs.min()+1\n",
    "        visited_e = torch.full((e_ptr[-1],), False, dtype = torch.bool)\n",
    "        for i in range(e_ind_start.shape[0]):\n",
    "            visited_e[e_ptr[:-1][i] :e_ind_start[i]] = True # setting emask True for edges in graph\n",
    "        edges_num = torch.arange(e_ptr[-1])\n",
    "\n",
    "        visited_v = torch.full((data.ptr[-1],), False)\n",
    "        visited_v[torch.unique(data.edge_index[:, visited_e])] = True\n",
    "        \n",
    "        last_ind_v = torch.arange(data.ptr[-1])\n",
    "        print(last_ind_v)\n",
    "                \n",
    "#         for i in range(szs.min()-1): #growing the graph\n",
    "        for i in range(data.edge_index.shape[1]):\n",
    "            if torch.all(visited_e):\n",
    "                break           \n",
    "            ei_graph = data.edge_index[:, visited_e]\n",
    "            ei_graph = torch.cat((ei_graph,torch.flip(ei_graph, [0])), dim=1)\n",
    "                                  \n",
    "            e1_mask = (visited_v[data.edge_index[0]] | visited_v[data.edge_index[1]]) & ~visited_e # Source in graph\n",
    "            nnedges = edges_num[e1_mask]\n",
    "            e1_ind = []\n",
    "            for j in range(1, e_ptr.shape[0]):\n",
    "                mmask = (nnedges < e_ptr[j]) & (nnedges >= e_ptr[j-1])\n",
    "                e1_ind.append(nnedges[mmask][:step])         \n",
    "            e1_ind = torch.cat(e1_ind)\n",
    "            edges_1 = data.edge_index[:, e1_ind]\n",
    "            \n",
    "            print(edges_1)\n",
    "                        \n",
    "            # selecting source-target when both vertices in graph            \n",
    "            edges_1 = torch.where(visited_v[edges_1[0]], edges_1,torch.flip(edges_1, [0]))            \n",
    "            visited_e[e1_ind] = True  \n",
    "            visited_v[edges_1.view(-1)] = True\n",
    "            \n",
    "            print(ei_graph.shape, edges_1.shape)\n",
    "            yield ei_graph, edges_1\n",
    "        \n",
    "        \n",
    "itt = iter(data_gen_e_connected(train_loader, dd.slices['edge_index'], batch_size = BSIZE,step = 1))\n",
    "g, e1 = next(itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_edges(data, batch_size = 4, step = 8):\n",
    "    istart = step\n",
    "    n_edges = data.edge_index.shape[1]\n",
    "    e_perm_edges = []\n",
    "    for i in range(batch_size):\n",
    "        e_perm_edges.append(data.edge_index[:,torch.randperm(n_edges)] + data.num_nodes *i)\n",
    "    e_perm_edges = torch.stack(e_perm_edges)\n",
    "    edge_index =  torch.transpose(e_perm_edges, 0, 1)\n",
    "\n",
    "    active_mask = torch.full((data.num_nodes * batch_size,), False,  dtype=torch.bool)\n",
    "    visited_mask = torch.full((data.num_nodes * batch_size,), False,  dtype=torch.bool)\n",
    "    nodes = torch.arange(batch_size*data.num_nodes)\n",
    "    visited_mask[torch.flatten(edge_index[:,:,:istart])] = True \n",
    "\n",
    "    for i in range(istart+step, n_edges, step):\n",
    "        # *********  sampling edges\n",
    "        graph = edge_index[:,:,:(i-step)]\n",
    "        e_1 = edge_index[:,:,(i-step):i]\n",
    "\n",
    "        # *********  node expansion\n",
    "        active_mask.fill_(False)  \n",
    "        active_mask[torch.flatten(e_1)] = True  \n",
    "        v_exp_0_mask = visited_mask & ~active_mask # in graph but not expanding\n",
    "        v_exp_1_mask = visited_mask & active_mask  # in graph AND expanding\n",
    "        n_e_1 = v_exp_1_mask.sum()\n",
    "        v_exp_1 = nodes[v_exp_1_mask]\n",
    "        v_exp_0 = nodes[v_exp_0_mask][:n_e_1]\n",
    "\n",
    "        # *********  node additon\n",
    "        v_add_1_mask = active_mask & ~visited_mask\n",
    "        \n",
    "        v_add_0_mask = ~visited_mask \n",
    "        n_v_1 = v_add_1_mask.sum()\n",
    "        v_left = nodes[v_add_0_mask]\n",
    "        v_add_0 = v_left[torch.randperm(v_left.shape[0])][:n_v_1]\n",
    "        v_add_1 = nodes[v_add_1_mask]\n",
    "        # print(n_v_1, n_e_1)\n",
    "\n",
    "        # *********  negative edges \n",
    "        r1,c1 = e_1\n",
    "        c0 = torch.zeros(size=c1.shape)\n",
    "        c0[:, 0] = c1[:, -1]\n",
    "        c0[:, 1:] = c1[:, :-1]\n",
    "        e_0 = torch.stack( (r1,c0))\n",
    "            \n",
    "        yield graph.reshape((2,-1)), \\\n",
    "                v_add_1_mask.view((batch_size, data.num_nodes)).sum(dim=1),\\\n",
    "                torch.cat((v_exp_0,v_exp_1)),\\\n",
    "                torch.cat((v_add_0,v_add_1)), \\\n",
    "                torch.cat((e_0,e_1), dim=2).reshape((2,-1)).to(dtype = torch.long),\\\n",
    "                visited_mask.view((batch_size, data.num_nodes))\n",
    "\n",
    "        visited_mask = visited_mask | v_add_1_mask  # add new to visited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "genv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
