{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os.path as osp\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from typing import List, Optional, Set, get_type_hints\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "from torch_scatter import gather_csr, scatter, segment_csr\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Sequential, ReLU, Linear, Dropout, BatchNorm1d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# from src.data_preparation import RWDataset, data_gen_e_aug\n",
    "# from src.models import GraphNet, add_weight_decay\n",
    "# from src.utils import create_nx_graph,create_gt_graph, draw_deg_distr, relabel, init_graph\n",
    "# from src.utils import sel_start_node, sel_start_node_old, get_errors\n",
    "# from src.train import LabelSmoothing\n",
    "# from src.utils import NodeSelector\n",
    "from src.model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PYG_datasets(path, d_name = 'PROTEINS'):\n",
    "    pth = path\n",
    "    path = osp.join(pathlib.Path().absolute(), pth , d_name)\n",
    "    dset = TUDataset(path, d_name)\n",
    "    \n",
    "    #sozdal otdelno pole features, a v pole x pomestil indexi - t.k. vektora vershin u nas menyayutsya\n",
    "    dset.features = dset.data.x \n",
    "    dset.data.x = torch.arange(dset.data.x.shape[0])\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = load_PYG_datasets(path='./data/proteins', d_name='PROTEINS')\n",
    "\n",
    "#dset = RWDataset('')  random walks for Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSIZE = 16\n",
    "train_loader = DataLoader(dset, batch_size=BSIZE, shuffle=False)# , exclude_keys=['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_e_aug(train_loader, slices, batch_size = 4, step = 1):\n",
    "    r\"\"\" berem skleennie graphi, iteriruem po vershinam, stroim augmented graph\n",
    "\n",
    "    Args:\n",
    "        train_loader: PyG DataLoader\n",
    "        slices: indexy reber, po kotorim skleivali nabor graphov\n",
    "        batch_size:\n",
    "        step: po skolko reber narashivaem graph, obichno 1\n",
    "    Outputs:\n",
    "        vi: indexi vershin v ishodnom graphe\n",
    "        graph: augmented graph\n",
    "        edges: priroshennie rebra\n",
    "    \"\"\"\n",
    "    \n",
    "    for ib, data in enumerate(train_loader):\n",
    "        print(data)\n",
    "        e_ptr = slices[ib*batch_size:(ib+1)*batch_size+1]\n",
    "        e_ptr = e_ptr - e_ptr[0]\n",
    "        szs = e_ptr[1:]-e_ptr[:-1]\n",
    "        e_ind_start = e_ptr[1:]-szs.min()+1\n",
    "        visited_e = torch.full((e_ptr[-1],), False, dtype = torch.bool)\n",
    "        for i in range(e_ind_start.shape[0]):\n",
    "            visited_e[e_ptr[:-1][i] :e_ind_start[i]] = True # setting emask True for edges in graph\n",
    "        edges_num = torch.arange(e_ptr[-1])\n",
    "        \n",
    "        visited_v = torch.full((data.ptr[-1],), False)\n",
    "        visited_v[torch.unique(data.edge_index[:, visited_e])] = True\n",
    "        \n",
    "        vert_base = torch.where(visited_v)[0]\n",
    "        \n",
    "        vert_ind,v_feature_ind = [], []\n",
    "        last_ind_v = torch.arange(data.ptr[-1])\n",
    "        last_ind_max = data.ptr[-1].item()        \n",
    "        ei_dict = defaultdict(set)\n",
    "        for e in data.edge_index[:, visited_e].T:\n",
    "            e = e.to(dtype=torch.long)\n",
    "            ei_dict[e[0].item()].add(e[1].item()) \n",
    "            ei_dict[e[1].item()].add(e[0].item()) \n",
    "        edge_added = []\n",
    "        \n",
    "        for i in range(data.edge_index.shape[1]): # max number of iterations, usually we stop earlier\n",
    "            if torch.all(visited_e):\n",
    "                break           \n",
    "                  \n",
    "            e1_mask = (visited_v[data.edge_index[0]] | visited_v[data.edge_index[1]]) & ~visited_e # Source in graph\n",
    "            nnedges = edges_num[e1_mask]\n",
    "            e1_ind = []\n",
    "            for j in range(1, e_ptr.shape[0]):\n",
    "                mmask = (nnedges < e_ptr[j]) & (nnedges >= e_ptr[j-1])\n",
    "                e1_ind.append(nnedges[mmask][:step])         \n",
    "            e1_ind = torch.cat(e1_ind)\n",
    "            edges_1 = data.edge_index[:, e1_ind]\n",
    "            \n",
    "            for e in edges_1.T: \n",
    "                e_reind = []\n",
    "                edge_added.append(last_ind_v[e].view(-1,1))\n",
    "                \n",
    "                for iv in (True,False):\n",
    "                    ind = last_ind_v[e[int(iv)]].item()\n",
    "                    vert_ind.append(ind)\n",
    "                    v_feature_ind.append(e[int(iv)])\n",
    "                    if ind in ei_dict.keys():\n",
    "                        ind = last_ind_max                        \n",
    "                        last_ind_v[e[int(iv)]] = ind\n",
    "                        ei_dict[ind] = ei_dict[e[int(iv)].item()]   \n",
    "                        last_ind_max += 1  \n",
    "                    e_reind.append(ind)\n",
    "                    \n",
    "                ei_dict[e_reind[0]].add(e_reind[1]) #sporno\n",
    "                ei_dict[e_reind[1]].add(e_reind[0])\n",
    "        \n",
    "            # selecting source-target when both vertices in graph            \n",
    "            visited_e[e1_ind] = True  \n",
    "            visited_v[edges_1.view(-1)] = True\n",
    "        \n",
    "        edge_index = []\n",
    "        for k,v in ei_dict.items():\n",
    "            e = torch.tensor(list(v)).view(1,-1)\n",
    "            edge_index.append(torch.cat((e, torch.full_like(e, k)), dim=0))\n",
    "\n",
    "\n",
    "        yield  data.x[torch.cat((torch.Tensor(v_feature_ind).to(dtype=torch.long),vert_base))],\\\n",
    "                torch.cat((torch.Tensor(vert_ind).to(dtype=torch.long),last_ind_v)), \\\n",
    "                torch.cat(edge_added, dim=1),\\\n",
    "                torch.cat(edge_index, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,  42,  69,  79, 103, 114, 450, 558, 712, 731, 742, 762, 814, 835,\n",
      "        879, 899, 939])\n",
      "torch.Size([16, 336]) tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "for ib, data in enumerate(train_loader):\n",
    "    print(data.ptr)\n",
    "    szs =data.ptr[1:]-data.ptr[:-1]\n",
    "    r = repeat(torch.arange(szs.max()), 'h -> h c', c=16).T\n",
    "    mask = r < szs.unsqueeze(1)\n",
    "    print(mask.shape, mask)\n",
    "    \n",
    "#     print(r.shape,data.ptr[1:].unsqueeze(1).shape)\n",
    "#     print(szs.max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szs =e_ptr[1:]-e_ptr[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen_e_aug(train_loader, dset.slices['edge_index'], batch_size = BSIZE,step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[939], edge_index=[2, 3928], ptr=[17], x=[939], y=[16])\n"
     ]
    }
   ],
   "source": [
    "itt = iter(train_gen)\n",
    "vi, vj, e1, graph = next(itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1964])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1995])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "    \n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "arch0 = {'input_dim': dset.features.shape[1], \n",
    "        'hidden_dim': 32,\n",
    "        'num_layers': 2,\n",
    "        'num_heads': 8,\n",
    "        'attn_pdrop': 0.5,\n",
    "        'resid_pdrop': 0.5,\n",
    "        'embd_pdrop': 0.5,\n",
    "        'gnn_pdrop': 0.5,\n",
    "        'num_gnn_layers': 1,\n",
    "        'mlp_pdrop': 0.5}\n",
    "conf = objectview(arch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, dropout_p = 0.2):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(num_features=hidden_dim))\n",
    "            \n",
    "    def forward(self, v_ind, features, edge_index):\n",
    "        x = features[v_ind]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.lin = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z_true, z_concat):\n",
    "        h = torch.abs(z_true - self.lin(z_concat)) \n",
    "\n",
    "        return self.lin_final(h)\n",
    "    \n",
    "    \n",
    "class SRAN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SRAN, self).__init__()\n",
    "\n",
    "        self.input_dim = config.input_dim\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.num_layers = config.num_layers\n",
    "        self.num_heads = config.num_heads\n",
    "        self.attn_pdrop = config.attn_pdrop\n",
    "        self.resid_pdrop = config.resid_pdrop\n",
    "        self.embd_pdrop = config.embd_pdrop\n",
    "        self.gnn_pdrop  = config.gnn_pdrop\n",
    "        self.num_gnn_layers = config.num_gnn_layers\n",
    "        self.mlp_pdrop = config.mlp_pdrop\n",
    "\n",
    "        self.lin_inp = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_dim)\n",
    "#             nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "#             nn.Dropout(self.mlp_pdrop)\n",
    "        )\n",
    "\n",
    "        self.gnn = GraphNet(\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_layers=self.num_gnn_layers,\n",
    "        )\n",
    "\n",
    "        self.gpt = GPT(\n",
    "            hidden_dim=2 * self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            attn_pdrop=self.attn_pdrop,\n",
    "            resid_pdrop=self.resid_pdrop,\n",
    "            embd_pdrop=self.embd_pdrop\n",
    "        )\n",
    "        \n",
    "        self.lp = LinkPredictor(2 * self.hidden_dim)\n",
    "        \n",
    "    def forward(self, v_ind, features, edge_index, edges):\n",
    "        feat = self.lin_inp(features)\n",
    "        print(v_ind.shape)\n",
    "\n",
    "        gnn_feat = self.gnn(v_ind, feat, edge_index) # (N,d)\n",
    "\n",
    "        edge_embs_true = rearrange(gnn_feat[edges], \n",
    "                                   'e batch n_seq d -> n_seq batch (d e)')# (S, N, d)\n",
    "        next_edge_embs = self.gpt(edge_embs_true[:-1])\n",
    "        \n",
    "        \n",
    "\n",
    "        return next_edge_embs\n",
    "\n",
    "\n",
    "        \n",
    "#         h_next_e = self.gpt(torch.cat((h_source, h_target)))\n",
    "        \n",
    "# #         y_source = self.choice(self.mlp_y_s(h_next_e), h_source) # сместить на 1 позицию\n",
    "# #         z_target = self.mlp_y_t(torch.cat((h_next_e, h_source))) #а здесь не смещаить h_source?\n",
    "# #         y_target = self.choice(z_target, h_target)\n",
    "        \n",
    "#         return h_next_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRAN(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1964])\n"
     ]
    }
   ],
   "source": [
    "y = model(vi, dset.features, graph, e1.view(2, BSIZE,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, -1]' is invalid for input of size 1995",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-f26c1bbcd729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16, -1]' is invalid for input of size 1995"
     ]
    }
   ],
   "source": [
    "vj.view(BSIZE, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 64])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 34,  33,  61,  ..., 898, 937, 938]),\n",
       " tensor([[  33,   59,   69,  ..., 1927, 1929, 1931],\n",
       "         [  34,   61,   71,  ..., 1799, 1833, 1867]]),\n",
       " tensor([[  32,   11,   22,  ..., 1867, 1930, 1962],\n",
       "         [   0,    0,    0,  ..., 1963, 1963, 1963]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi, e1, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  33,   59,   69,  ..., 1927, 1929, 1931],\n",
       "        [  34,   61,   71,  ..., 1799, 1833, 1867]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.block_size, \"Cannot forward, model block size is exhausted.\"\n",
    "\n",
    "        # forward the GPT model\n",
    "        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector\n",
    "        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector\n",
    "        x = self.drop(token_embeddings + position_embeddings)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-720dac183943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-954f761b95ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, v_ind, features, edge_index, edges)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_inp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mgnn_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-954f761b95ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, v_ind, features, edge_index)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Otherwise, run both functions in separation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             coll_dict = self.__collect__(self.__user_args__, edge_index, size,\n\u001b[0m\u001b[1;32m    234\u001b[0m                                          kwargs)\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_size__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     data = self.__lift__(data, edge_index,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                          j if arg[-2:] == '_j' else i)\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__lift__\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  6.8156e-01,  7.3176e-01,  5.3317e-01,\n",
      "          8.4601e-01,  4.0931e-01,  9.1240e-01,  3.1098e-01,  9.5042e-01,\n",
      "          2.3492e-01,  9.7201e-01,  1.7689e-01,  9.8423e-01,  1.3296e-01,\n",
      "          9.9112e-01,  9.9833e-02,  9.9500e-01,  7.4919e-02,  9.9719e-01,\n",
      "          5.6204e-02,  9.9842e-01,  4.2157e-02,  9.9911e-01,  3.1618e-02,\n",
      "          9.9950e-01,  2.3712e-02,  9.9972e-01,  1.7782e-02,  9.9984e-01,\n",
      "          1.3335e-02,  9.9991e-01,  9.9998e-03,  9.9995e-01,  7.4989e-03,\n",
      "          9.9997e-01,  5.6234e-03,  9.9998e-01,  4.2170e-03,  9.9999e-01,\n",
      "          3.1623e-03,  9.9999e-01,  2.3714e-03,  1.0000e+00,  1.7783e-03,\n",
      "          1.0000e+00,  1.3335e-03,  1.0000e+00,  1.0000e-03,  1.0000e+00,\n",
      "          7.4989e-04,  1.0000e+00,  5.6234e-04,  1.0000e+00,  4.2170e-04,\n",
      "          1.0000e+00,  3.1623e-04,  1.0000e+00,  2.3714e-04,  1.0000e+00,\n",
      "          1.7783e-04,  1.0000e+00,  1.3335e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.9748e-01,  7.0948e-02,  9.0213e-01,\n",
      "          4.3146e-01,  7.4690e-01,  6.6493e-01,  5.9113e-01,  8.0658e-01,\n",
      "          4.5669e-01,  8.8962e-01,  3.4821e-01,  9.3742e-01,  2.6355e-01,\n",
      "          9.6464e-01,  1.9867e-01,  9.8007e-01,  1.4942e-01,  9.8877e-01,\n",
      "          1.1223e-01,  9.9368e-01,  8.4239e-02,  9.9645e-01,  6.3203e-02,\n",
      "          9.9800e-01,  4.7410e-02,  9.9888e-01,  3.5558e-02,  9.9937e-01,\n",
      "          2.6667e-02,  9.9964e-01,  1.9999e-02,  9.9980e-01,  1.4997e-02,\n",
      "          9.9989e-01,  1.1247e-02,  9.9994e-01,  8.4338e-03,  9.9996e-01,\n",
      "          6.3245e-03,  9.9998e-01,  4.7427e-03,  9.9999e-01,  3.5566e-03,\n",
      "          9.9999e-01,  2.6670e-03,  1.0000e+00,  2.0000e-03,  1.0000e+00,\n",
      "          1.4998e-03,  1.0000e+00,  1.1247e-03,  1.0000e+00,  8.4339e-04,\n",
      "          1.0000e+00,  6.3246e-04,  1.0000e+00,  4.7427e-04,  1.0000e+00,\n",
      "          3.5566e-04,  1.0000e+00,  2.6670e-04,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  7.7827e-01, -6.2793e-01,  9.9325e-01,\n",
      "         -1.1597e-01,  9.5363e-01,  3.0097e-01,  8.1265e-01,  5.8275e-01,\n",
      "          6.5290e-01,  7.5744e-01,  5.0854e-01,  8.6104e-01,  3.8947e-01,\n",
      "          9.2104e-01,  2.9552e-01,  9.5534e-01,  2.2308e-01,  9.7480e-01,\n",
      "          1.6790e-01,  9.8580e-01,  1.2617e-01,  9.9201e-01,  9.4726e-02,\n",
      "          9.9550e-01,  7.1081e-02,  9.9747e-01,  5.3323e-02,  9.9858e-01,\n",
      "          3.9995e-02,  9.9920e-01,  2.9995e-02,  9.9955e-01,  2.2495e-02,\n",
      "          9.9975e-01,  1.6869e-02,  9.9986e-01,  1.2651e-02,  9.9992e-01,\n",
      "          9.4867e-03,  9.9995e-01,  7.1141e-03,  9.9997e-01,  5.3348e-03,\n",
      "          9.9999e-01,  4.0006e-03,  9.9999e-01,  3.0000e-03,  1.0000e+00,\n",
      "          2.2497e-03,  1.0000e+00,  1.6870e-03,  1.0000e+00,  1.2651e-03,\n",
      "          1.0000e+00,  9.4868e-04,  1.0000e+00,  7.1141e-04,  1.0000e+00,\n",
      "          5.3348e-04,  1.0000e+00,  4.0006e-04,  1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  1.4154e-01, -9.8993e-01,  7.7847e-01,\n",
      "         -6.2768e-01,  9.9328e-01, -1.1573e-01,  9.5358e-01,  3.0114e-01,\n",
      "          8.1257e-01,  5.8286e-01,  6.5283e-01,  7.5751e-01,  5.0847e-01,\n",
      "          8.6108e-01,  3.8942e-01,  9.2106e-01,  2.9548e-01,  9.5535e-01,\n",
      "          2.2304e-01,  9.7481e-01,  1.6788e-01,  9.8581e-01,  1.2615e-01,\n",
      "          9.9201e-01,  9.4713e-02,  9.9550e-01,  7.1071e-02,  9.9747e-01,\n",
      "          5.3316e-02,  9.9858e-01,  3.9989e-02,  9.9920e-01,  2.9991e-02,\n",
      "          9.9955e-01,  2.2492e-02,  9.9975e-01,  1.6867e-02,  9.9986e-01,\n",
      "          1.2649e-02,  9.9992e-01,  9.4854e-03,  9.9995e-01,  7.1131e-03,\n",
      "          9.9997e-01,  5.3341e-03,  9.9999e-01,  4.0000e-03,  9.9999e-01,\n",
      "          2.9996e-03,  1.0000e+00,  2.2494e-03,  1.0000e+00,  1.6868e-03,\n",
      "          1.0000e+00,  1.2649e-03,  1.0000e+00,  9.4855e-04,  1.0000e+00,\n",
      "          7.1131e-04,  1.0000e+00,  5.3341e-04,  1.0000e+00],\n",
      "        [-9.5892e-01,  2.8366e-01, -5.7113e-01, -8.2086e-01,  3.2394e-01,\n",
      "         -9.4608e-01,  8.5890e-01, -5.1215e-01,  9.9995e-01, -1.0342e-02,\n",
      "          9.2676e-01,  3.7566e-01,  7.7653e-01,  6.3008e-01,  6.1844e-01,\n",
      "          7.8583e-01,  4.7943e-01,  8.7758e-01,  3.6622e-01,  9.3053e-01,\n",
      "          2.7748e-01,  9.6073e-01,  2.0929e-01,  9.7785e-01,  1.5746e-01,\n",
      "          9.8753e-01,  1.1829e-01,  9.9298e-01,  8.8797e-02,  9.9605e-01,\n",
      "          6.6627e-02,  9.9778e-01,  4.9979e-02,  9.9875e-01,  3.7486e-02,\n",
      "          9.9930e-01,  2.8113e-02,  9.9960e-01,  2.1083e-02,  9.9978e-01,\n",
      "          1.5811e-02,  9.9988e-01,  1.1857e-02,  9.9993e-01,  8.8913e-03,\n",
      "          9.9996e-01,  6.6676e-03,  9.9998e-01,  5.0000e-03,  9.9999e-01,\n",
      "          3.7495e-03,  9.9999e-01,  2.8117e-03,  1.0000e+00,  2.1085e-03,\n",
      "          1.0000e+00,  1.5811e-03,  1.0000e+00,  1.1857e-03,  1.0000e+00,\n",
      "          8.8914e-04,  1.0000e+00,  6.6676e-04,  1.0000e+00],\n",
      "        [-2.7942e-01,  9.6017e-01, -9.7740e-01, -2.1142e-01, -2.3037e-01,\n",
      "         -9.7310e-01,  5.7403e-01, -8.1884e-01,  9.4715e-01, -3.2080e-01,\n",
      "          9.8907e-01,  1.4743e-01,  8.7574e-01,  4.8278e-01,  7.1743e-01,\n",
      "          6.9663e-01,  5.6464e-01,  8.2534e-01,  4.3491e-01,  9.0047e-01,\n",
      "          3.3104e-01,  9.4362e-01,  2.5033e-01,  9.6816e-01,  1.8860e-01,\n",
      "          9.8205e-01,  1.4180e-01,  9.8989e-01,  1.0649e-01,  9.9431e-01,\n",
      "          7.9926e-02,  9.9680e-01,  5.9964e-02,  9.9820e-01,  4.4978e-02,\n",
      "          9.9899e-01,  3.3734e-02,  9.9943e-01,  2.5299e-02,  9.9968e-01,\n",
      "          1.8973e-02,  9.9982e-01,  1.4228e-02,  9.9990e-01,  1.0669e-02,\n",
      "          9.9994e-01,  8.0010e-03,  9.9997e-01,  6.0000e-03,  9.9998e-01,\n",
      "          4.4993e-03,  9.9999e-01,  3.3740e-03,  9.9999e-01,  2.5302e-03,\n",
      "          1.0000e+00,  1.8974e-03,  1.0000e+00,  1.4228e-03,  1.0000e+00,\n",
      "          1.0670e-03,  1.0000e+00,  8.0011e-04,  1.0000e+00],\n",
      "        [ 6.5699e-01,  7.5390e-01, -8.5931e-01,  5.1145e-01, -7.1372e-01,\n",
      "         -7.0043e-01,  1.8858e-01, -9.8206e-01,  8.0042e-01, -5.9944e-01,\n",
      "          9.9603e-01, -8.9047e-02,  9.4733e-01,  3.2026e-01,  8.0369e-01,\n",
      "          5.9505e-01,  6.4422e-01,  7.6484e-01,  5.0115e-01,  8.6536e-01,\n",
      "          3.8355e-01,  9.2352e-01,  2.9092e-01,  9.5675e-01,  2.1956e-01,\n",
      "          9.7560e-01,  1.6523e-01,  9.8625e-01,  1.2416e-01,  9.9226e-01,\n",
      "          9.3211e-02,  9.9565e-01,  6.9943e-02,  9.9755e-01,  5.2468e-02,\n",
      "          9.9862e-01,  3.9354e-02,  9.9923e-01,  2.9514e-02,  9.9956e-01,\n",
      "          2.2134e-02,  9.9976e-01,  1.6599e-02,  9.9986e-01,  1.2448e-02,\n",
      "          9.9992e-01,  9.3345e-03,  9.9996e-01,  6.9999e-03,  9.9998e-01,\n",
      "          5.2492e-03,  9.9999e-01,  3.9364e-03,  9.9999e-01,  2.9519e-03,\n",
      "          1.0000e+00,  2.2136e-03,  1.0000e+00,  1.6600e-03,  1.0000e+00,\n",
      "          1.2448e-03,  1.0000e+00,  9.3346e-04,  1.0000e+00],\n",
      "        [ 9.8936e-01, -1.4550e-01, -2.8023e-01,  9.5993e-01, -9.7726e-01,\n",
      "         -2.1204e-01, -2.2990e-01, -9.7321e-01,  5.7432e-01, -8.1863e-01,\n",
      "          9.4723e-01, -3.2054e-01,  9.8904e-01,  1.4763e-01,  8.7567e-01,\n",
      "          4.8291e-01,  7.1736e-01,  6.9671e-01,  5.6457e-01,  8.2538e-01,\n",
      "          4.3485e-01,  9.0050e-01,  3.3099e-01,  9.4363e-01,  2.5029e-01,\n",
      "          9.6817e-01,  1.8857e-01,  9.8206e-01,  1.4178e-01,  9.8990e-01,\n",
      "          1.0648e-01,  9.9431e-01,  7.9915e-02,  9.9680e-01,  5.9956e-02,\n",
      "          9.9820e-01,  4.4972e-02,  9.9899e-01,  3.3729e-02,  9.9943e-01,\n",
      "          2.5296e-02,  9.9968e-01,  1.8970e-02,  9.9982e-01,  1.4226e-02,\n",
      "          9.9990e-01,  1.0668e-02,  9.9994e-01,  7.9999e-03,  9.9997e-01,\n",
      "          5.9991e-03,  9.9998e-01,  4.4987e-03,  9.9999e-01,  3.3736e-03,\n",
      "          9.9999e-01,  2.5298e-03,  1.0000e+00,  1.8971e-03,  1.0000e+00,\n",
      "          1.4226e-03,  1.0000e+00,  1.0668e-03,  1.0000e+00],\n",
      "        [ 4.1212e-01, -9.1113e-01,  4.4919e-01,  8.9343e-01, -9.3982e-01,\n",
      "          3.4166e-01, -6.0811e-01, -7.9385e-01,  2.9126e-01, -9.5664e-01,\n",
      "          8.4542e-01, -5.3410e-01,  9.9956e-01, -2.9651e-02,  9.3210e-01,\n",
      "          3.6220e-01,  7.8333e-01,  6.2161e-01,  6.2482e-01,  7.8077e-01,\n",
      "          4.8478e-01,  8.7464e-01,  3.7048e-01,  9.2884e-01,  2.8078e-01,\n",
      "          9.5977e-01,  2.1181e-01,  9.7731e-01,  1.5936e-01,  9.8722e-01,\n",
      "          1.1973e-01,  9.9281e-01,  8.9879e-02,  9.9595e-01,  6.7439e-02,\n",
      "          9.9772e-01,  5.0589e-02,  9.9872e-01,  3.7944e-02,  9.9928e-01,\n",
      "          2.8457e-02,  9.9960e-01,  2.1341e-02,  9.9977e-01,  1.6004e-02,\n",
      "          9.9987e-01,  1.2001e-02,  9.9993e-01,  8.9999e-03,  9.9996e-01,\n",
      "          6.7490e-03,  9.9998e-01,  5.0611e-03,  9.9999e-01,  3.7953e-03,\n",
      "          9.9999e-01,  2.8460e-03,  1.0000e+00,  2.1342e-03,  1.0000e+00,\n",
      "          1.6005e-03,  1.0000e+00,  1.2002e-03,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.randn(100, 16)\n",
    "v2 = torch.randn(100, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"n1 d1 n2 d2 -> (d1 d2) n1 n2\".\n Input tensor shape: torch.Size([2, 100, 16]). Additional info: {}.\n Expected 4 dimensions, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mrecipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_transformation_recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashable_axes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEinopsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes = self.reconstruct_from_shape(\n\u001b[0m\u001b[1;32m    205\u001b[0m             backend.shape(tensor))\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreconstruct_from_shape\u001b[0;34m(self, shape, optimize)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected {} dimensions, got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mknown_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munknown_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m: Expected 4 dimensions, got 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-681571b31be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n1 d1 n2 d2 -> (d1 d2) n1 n2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rearrange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/genv/lib/python3.8/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n Input is list. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Additional info: {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"n1 d1 n2 d2 -> (d1 d2) n1 n2\".\n Input tensor shape: torch.Size([2, 100, 16]). Additional info: {}.\n Expected 4 dimensions, got 3"
     ]
    }
   ],
   "source": [
    "tensors = rearrange([v1,v2], 'n1 d1 n2 d2 -> (d1 d2) n1 n2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eshe ne pravil!!!!\n",
    "\n",
    "def train(sampler, mod, optimizer, data, bsz):\n",
    "    mod.train()\n",
    "        \n",
    "    loss = 0   \n",
    "    encoded_features = mod.encode(data.x.to(device = mod.device))\n",
    "\n",
    "    ii=0\n",
    "    for inp in sampler(data, batch_size = bsz):\n",
    "        ii +=1\n",
    "        encoded_features = mod.encode(data.x.to(device = mod.device))\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        pred_e, targ_e, w0 = mod.iterate(data, inp, encoded, bsz) \n",
    "#         n_1.append(targ_e.sum())\n",
    "#         num_e.append(pred_e.shape[0])\n",
    "        if mod.label_smooth:\n",
    "            loss += cal_edge_loss(pred_e, targ_e)\n",
    "        else:\n",
    "            loss += F.binary_cross_entropy_with_logits(pred_e, targ_e)    \n",
    "#             loss += F.binary_cross_entropy_with_logits(pred_e, targ_e, \n",
    "#                                                        pos_weight = torch.tensor([w0], device = mod.device))    \n",
    "            \n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "#     d_train\n",
    "    train(data_gen_edges_dyn, model, optimizer, data, B_SIZE)\n",
    "#     train(data_gen_edges_dyn, model, optimizer, d_train, B_SIZE)\n",
    "#     train(data_gen_edges_dyn, model, optimizer, data, B_SIZE)\n",
    "#     acc_e_test = test( data_gen_edges_dyn, model, d_test, 1)\n",
    "#     acc_e_test = test( data_gen_edges_dyn, model, data, 1)\n",
    "#     acc = acc_e_test.mean()\n",
    "#     print(acc, np.median(acc_e_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eshe ne pravil!!!!\n",
    "@torch.no_grad()\n",
    "def test(sampler,mod, data, bsz, return_y = False, dtype = 'test'):\n",
    "    mod.eval()\n",
    "        \n",
    "    out = []\n",
    "    n_1, acc_e,num_e = [],[],[]\n",
    "    # init_state = torch.zeros((data.num_nodes*bsz,  mod.nd), device=mod.device)\n",
    "    encoded = mod.encode(data.x.to(device = mod.device))\n",
    "    indd = torch.cat(bsz*[torch.arange(data.num_nodes, device = mod.device)])\n",
    "    mod.reset_state(encoded[indd,:])\n",
    "    for inp in sampler(data, batch_size = bsz, step_max = 512, dtype = dtype):\n",
    "        pred_e, targ_e, w0 = mod.iterate(data, inp, encoded, bsz) \n",
    "        if return_y:\n",
    "            out.append((pred_e, targ_e, w0))#, dim=1\n",
    "        pred_e = torch.round(torch.sigmoid(pred_e))\n",
    "#         print('pred_e', pred_e)\n",
    "        tp_e = pred_e.eq(targ_e).sum().item()\n",
    "        n_e = pred_e.shape[0]\n",
    "        \n",
    "        n_1.append(targ_e.sum())\n",
    "\n",
    "        acc_e.append(tp_e)\n",
    "        num_e.append(n_e)\n",
    "        \n",
    "    if return_y:\n",
    "        return out\n",
    "    else:\n",
    "        return  np.array(acc_e)/(np.array(num_e)+1e-9)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "genv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
